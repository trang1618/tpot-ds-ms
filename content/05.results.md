## Results
Our main goal is to test the performance of methods to identify features that discriminate between groups and optimize the classification accuracy.

### TPOT-FSS recommends optimal pipelines
As discussed earlier in the Methods section, the optimal pipeline from TPOT-FSS and standard TPOT is selected to be closest to the 90th percentile of the cross-validation accuracy.
The optimal model of XGBoost holds properly tuned hyperparameters.
For simulated dataset, the optimal pipeline selects subset $S_1$ then constructs an approximate feature map for a linear kernel with Nystroem, which uses a subset of the data as the basis for the approximation.
The final prediction is made with an extra-trees classifier that fits a number of randomized decision trees on various sub-samples of the dataset with the presented optimized parameters (Fig. {@fig:flow}).
For the real-world dataset, the most optimal pipeline selects subset DGM-5, one-hot encode the features, then, similar to simulated data, makes the final prediction with an extra-trees classifier with a different set of optimized parameters (Fig. {@fig:flow}).

### Accuracy assessment of optimal pipelines
We compare the accuracy produced by optimal models from TPOT-FSS, standard TPOT and XGBoost on classifying a simulated dataset with moderate interaction effect.
We assign values of the effect size in the simulations to generate adequately challenging datasets so that the methods' accuracies stay moderate and do not cluster around 0.5 or 1.
The resulting accuracy values are comparable to those in real-world data.
The data set is split into 75% training and 25% holdout.
The three models are built from the training dataset, then the trained model is applied to the independent holdout data to obtain the holdout accuracy. 

We also apply the three methods to the RNA-Seq study of 78 major depressive disorder (MDD) subjects and 79 healthy controls (HC) described in [@doi:10.1038/s41398-018-0234-3].
The dataset contains 5,912 genes after preprocessing and filtering (see Methods for more detail).
We excluded 277 genes that did not belong to 23 subsets of interconnected genes (DGMs) so that the dataset remains the same across the three methods.
As with simulated data, all models are built from the training dataset (61 HC, 56 MDD), then the trained model is applied to the independent holdout data (18 HC, 22 MDD).

For the simulated data, across all 100 model fits, the optimal TPOT-FSS pipeline yields an average holdout prediction accuracy of 0.65, while the standard TPOT without FSS and tuned XGBoost models respectively report an average holdout accuracy of 0.48 and 0.49 (Fig. {@fig:compAcc}).
This overfitting in the performance of these other two models is likely due to the models' high flexibility that *over-learns* the training data, especially with the presence of many noisy background features.

![Performance comparison of three models: tuned XGBoost, optimal pipeline from standard TPOT and optimal pipeline from TPOT-FSS.](images/compareAcc.svg){#fig:compAcc width="90%"}

Meanwhile, for the real-world expression data, the optimal TPOT-FSS pipeline yields an average holdout prediction accuracy of 0.68, while the standard TPOT without FSS and tuned XGBoost models produce average holdout accuracies of 0.60 and 0.59 respectively across all 100 model fits (Fig. {@fig:compAcc}).
In summary, the optimal models from standard TPOT and XGBoost perform better in real-world data compared to simulated data but still worse than that of TPOT-FSS.
In both datasets, separate Welch two-sample one-sided *t*-tests show TPOT-FSS optimal pipelines significantly outperform those of XGBoost and standard TPOT (all *p* values $<10^{-15}$).

### Consistency in selecting subsets of TPOT-FSS

![TPOT-FSS's holdout accuracy in simulated data with selected subset. Number of pipeline inclusions of each subset in 100 replications is displayed above the boxplots. Subset $S_1$ is the most frequent to be included in the final pipeline and yields the best prediction accuracy in the holdout set.](images/sim_100.svg){#fig:simFSS width="100%"}

Our simulation design produces a reasonable distribution of the functional features in all subsets, of which proportions are shown in Table S1.
According to Eq. {@eq:p_subset}, the earlier the subset, the more functional features it has.
Therefore, our aim is to determine how well TPOT-FSS can identify the first subset ($S_1$) that contains the largest number of informative features.
In 100 replications, TPOT-FSS correctly selects subset $S_1$ in 75 resulting pipelines (Fig. {@fig:simFSS}), with the highest average holdout accuracy (0.69 across all 75 pipelines).

![TPOT-FSS's holdout accuracy in RNA-Seq expression data with selected subset. Number of pipeline inclusions of each subset in 100 replications is displayed above the boxplots. Subsets DGM-5 and DGM-13 are the most frequent to be included in the final pipeline. Pipelines that include DGM-5, on average, produce higher MDD prediction accuracies in the holdout set.](images/real_100.svg){#fig:realFSS width="80%"}

For the expression data, in 100 replications, TPOT-FSS selects DGM-5 (291 genes) 64 times to be the subset most predictive of the diagnosis status (Fig. {@fig:realFSS}), with the highest average holdout accuracy of 0.636 across 64 pipelines.
In the previous study with a modular network approach, we showed that DGM-5 has statistically significant associations with depression severity measured by the Montgomery-Ã…sberg Depression Scale (MADRS).
Although there is no direct link between the top genes of the module (Fig. {@fig:featImp}a) and MDD in the literature, many of these genes interact with other MDD-related genes.
For example, NR2C2 interacts with FKBP5 gene whose association with MDD has been strongly suggested [@doi:10.1016/j.jad.2010.02.113;@doi:10.1016/j.brainres.2009.06.036;@doi:10.1038/ng1479].
Many of DGM-5's top genes, including FAM13A, NR2C2,PP7080 and OXR1, were previously shown to have significant association with the diagnosis phenotype using a Relief-based feature selection method [@doi:10.1093/bioinformatics/bty788].
Further, with 82% overlap of DGM-5's genes in a separate dataset from the RNA-Seq study by Mostafavi et al. [@doi:10.1038/mp.2013.161], this gene collection's enrichment score was also shown to be significantly associated with the diagnosis status in this independent dataset.

![Permutation importance scores of the top twenty expression features in the optimal pipeline that selects DGM-5 and one that selects DGM-13. Comprehensive importance scores of the all expression features computed by permutation from the optimal pipelines are provided in Table S2.](images/importanceFeatures.svg){#fig:featImp width="100%"}

After DGM-5, DGM-13 (134 genes) was selected by TPOT-FSS 30 times (Fig. {@fig:realFSS}), with an average holdout accuracy of 0.563 across 30 pipelines.
The previous network approach did not find statistically significant association between this module's enrichment score and the MADRS.
While many of the top genes (Fig. {@fig:featImp}b) do not have direct disease association, several have been linked to depression-like behavior in animal studies such as PPP1R16A [@doi:10.1176/appi.ajp.2009.08121760] and CASKIN1 [@doi:10.1186/s13041-018-0407-2].
The RGL4 gene, a Ral guanine nucleotide dissociation stimulator, was found to have a rare protein disruptive variant in at least one suicide patient among 60 other mutations [@doi:10.1038/s41598-017-06522-3].

### Computational expense
For a dataset of the size simulated in our study (*m* = 200 samples and *p* = 5000 attributes), standard TPOT has a 18.5-hour runtime on a low performance computing machine with an Intel Xeon E5-2690 2.60GHz CPU, 28 cores and 256GB of RAM, whereas TPOT-FSS has a 65-minute runtime, approximately 17 times faster.
On the same low performance computing machine, each replication of standard TPOT on the expression data takes on average 13.3 hours, whereas TPOT-FSS takes 40 minutes, approximately 20 times faster.